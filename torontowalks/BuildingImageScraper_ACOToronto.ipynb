{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape labelled images of building styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACOToronto website contains the TOBuilt database -- an open source database of images and information about buildings and structures in toronto.\n",
    "http://www.acotoronto.ca/tobuilt_new_detailed.php\n",
    "\n",
    "Order of actions\n",
    "* we will first use the search tool on the main page to find all the available architectural styles (http://www.acotoronto.ca/tobuilt_new_detailed.php)\n",
    "* then we will call the page for each style.  This page contains a thumbnail image of each building classified in that style, a link for more details and basic info about the building.  \n",
    "Note: you generally have to follow a redirection to get to the style page\n",
    "(http://www.acotoronto.ca/search_buildingsR-d.php?sid=8065)\n",
    "* download the image locally to image/<style>\n",
    "* call building details page to get info on building dates, architects etc\n",
    "(http://www.acotoronto.ca/show_building.php?BuildingID=3883)\n",
    " page is structured with alternating building_info and building_info2 divs\n",
    "building_info contains the name of the info to follow\n",
    "building_info2 contains the value\n",
    "The companies row contains the architects. There can be muliple architects for a building, so these are < li > items.\n",
    "Sometimes the archtect is a hyperlink, but not always, so need to handle both cases specially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "American colonial\n",
    "Annex Style\n",
    "Art deco\n",
    "Arts and Crafts\n",
    "Beaux arts\n",
    "Brutalist\n",
    "Byzantine\n",
    "Chicago style\n",
    "Classical revival\n",
    "Commercial style\n",
    "Contemporary\n",
    "Deconstructivism\n",
    "Dutch colonial\n",
    "Early modern\n",
    "Edwardian classical\n",
    "English Cottage style\n",
    "Georgian revival\n",
    "Gothic revival\n",
    "Greek revival\n",
    "International style\n",
    "Italianate\n",
    "Late modernist\n",
    "Log construction\n",
    "Mid century expressionist\n",
    "Mirrored tower\n",
    "Modern classical\n",
    "Modern historicist\n",
    "Modernist\n",
    "Neo Palladian\n",
    "Neo-Chateau\n",
    "Neo-Georgian\n",
    "Neo-modernist\n",
    "Neo-Tudor\n",
    "Postmodern\n",
    "Prairie style\n",
    "Queen Anne\n",
    "Regency\n",
    "Renaissance revival\n",
    "Richardsonian Romanesque\n",
    "Romanesque revival\n",
    "Sculptural\n",
    "Second empire\n",
    "Shingle style\n",
    "Spanish colonial\n",
    "Toronto Bay and Gable\n",
    "Workers Cottage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import urllib\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from sqlalchemy import sql, Table, MetaData\n",
    "import ast\n",
    "from ast import literal_eval\n",
    "from create_db import connect_db\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Sequence, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models import connect_db, PointsOfInterest, ArchitecturalStyles, Architects,POICategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up base variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_page = 'http://www.acotoronto.ca/tobuilt_new_detailed.php'\n",
    "style_url=\"http://www.acotoronto.ca/search_buildingsDB_d2.php\"\n",
    "site_root = \"http://www.acotoronto.ca/\"\n",
    "debug=False\n",
    "buildings_list=[]\n",
    "rerun_webscrape=False # rerun all  webscraping\n",
    "populate_db = False # repopulate database\n",
    "\n",
    "df_to_db_map={\n",
    "    'Name':'name',\n",
    "    'Completed':'build_year'   ,\n",
    "    'Demolished' :'demolished_year',\n",
    "    'Address' :'address' ,\n",
    "    'Bld_link':'external_url',\n",
    "    'Notes': 'details',\n",
    "    'Image':'image_url',\n",
    "    'Heritage':'heritage_status',\n",
    "    'Current use':'current_use',\n",
    "    'Type':'poi_type'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        print(f\"Error connecting: status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(style, img_url):\n",
    "    '''\n",
    "    * downloads image to the appropriate style sub-folder in the images directory (and creates folder if missing)\n",
    "    * to test: download_image('test','/tobuilt_bk/php/Buildingimages/106BedfordRd.jpg')\n",
    "    '''\n",
    "\n",
    "    dest_dir = f\"../Images/{style}\"\n",
    "\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    full_url = f'{site_root}/{img_url}'\n",
    "    image_path = f\"{dest_dir}/{img_url.split('/')[-1]}\"\n",
    "    res = urllib.request.urlretrieve(full_url, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from https://michaeljsanders.com/2017/05/12/scrapin-and-scrollin.html\n",
    "def get_scrolling_page(page_url):\n",
    "    browser = webdriver.Chrome(\"C:\\\\Users\\\\blahjays\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "    # Tell Selenium to get the URL you're interested in.\n",
    "   # browser.get(\"http://www.acotoronto.ca/search_buildingsR-d.php?sid=8225\")\n",
    "    browser.get(page_url)\n",
    "\n",
    "    # Selenium script to scroll to the bottom, wait 3 seconds for the next batch of data to load, then continue scrolling.  It will continue to do this until the page stops loading new data.\n",
    "    lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "    match=False\n",
    "    while(match==False):\n",
    "            lastCount = lenOfPage\n",
    "            time.sleep(3)\n",
    "            lenOfPage = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "            if lastCount==lenOfPage:\n",
    "                match=True\n",
    "\n",
    "    # Now that the page is fully scrolled, grab the source code.\n",
    "    source_data = browser.page_source\n",
    "\n",
    "    # Throw your source into BeautifulSoup and start parsing!\n",
    "    bs_data = bs(source_data)\n",
    "    browser.close()\n",
    "    return bs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Details pages\n",
    "* page is structured with alternating building_info and building_info2 divs\n",
    "* building_info contains the name of the info to follow\n",
    "* building_info2 contains the value\n",
    "* The companies row contains the architects.  There can be muliple architects for a building, so these are < li > items.\n",
    "* Sometimes the archtect is a hyperlink, but not always, so need to handle both cases specially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_building_details(bld_link):\n",
    "    \n",
    "    flags_dict = {\n",
    "        'Completed':None,\n",
    "        'Demolished': None,\n",
    "        'Companies': None,\n",
    "        'Type':None,\n",
    "        'Current use': None,\n",
    "        'Heritage': None,\n",
    "       'Notes': None\n",
    "    }\n",
    "    architects=[]\n",
    "    \n",
    "    full_url = f'{site_root}{bld_link}'\n",
    "    html_bld = load_page(full_url)\n",
    "    soup_bld = BeautifulSoup(html_bld)\n",
    "    # get all building info elements\n",
    "    info = soup_bld.find_all('div',{'class': 'building_info'})\n",
    "    for inf in info:\n",
    "        for flag in flags_dict.keys():\n",
    "            if flag in inf.text:\n",
    "                if 'Companies' in flag:\n",
    "                    company_box = inf.find_next()\n",
    "\n",
    "                    if 'Architect - ' in company_box.text:\n",
    "                        li_items = company_box.find_all('li')\n",
    "\n",
    "                        for arc in li_items:\n",
    "                            if (arc.find('span')):\n",
    "                                architect = arc.find('span').previousSibling\n",
    "                                if architect.name =='a':\n",
    "                                    architects.append(architect.text.strip())\n",
    "                                else:\n",
    "                                    architects.append(architect.replace('-','').strip())\n",
    "                                \n",
    "                        flags_dict[flag] = architects\n",
    "                else:\n",
    "                    flags_dict[flag] = inf.find_next().text.strip()\n",
    "    return flags_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Buildings for style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buildings_for_style(soup, style):\n",
    "    buildings=[]\n",
    "   \n",
    "    for building in soup.find_all('div',{'class': 'box'}):\n",
    "        build_style = building.find('div',{'class': 'box_image'})['style']\n",
    "        image_url = re.findall('\\((.*?)\\)', build_style)[0]\n",
    "        build_dict={\n",
    "            'Style':style,\n",
    "            'Name':building.findChild('span',{'class':'title'}).text,\n",
    "            'Bld_link':building.findChild('a').get_attribute_list(key='href')[0],\n",
    "            'Image':image_url,\n",
    "            'Address': str(building.findChild('div',{'class':'the_box_text'}).findChild('p')).replace('<br/>',' ').replace('<p>','').replace('</p>','')\n",
    "        }\n",
    "\n",
    "        download_image(style,image_url)\n",
    "        #follow link to get more info on building\n",
    "        if debug==True: \n",
    "            print(build_dict['Bld_link'])\n",
    "        build_details_dict = get_building_details(build_dict['Bld_link'])\n",
    "        build_dict = {**build_dict, **build_details_dict}\n",
    "        buildings.append(build_dict)\n",
    "   # bld_df = pd.DataFrame(buildings)\n",
    "    return buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_style (style):\n",
    "    '''\n",
    "    Test: #process_style('Arts and Crafts')\n",
    "    '''\n",
    "    print (f\"loading {style}\")\n",
    "    curr_style_url = f\"{style_url}?MainStyle={style}\"\n",
    "    soup=get_scrolling_page(curr_style_url)\n",
    "    print(curr_style_url)\n",
    "#     html = load_page(curr_style_url)\n",
    "#     soup = BeautifulSoup(html)\n",
    "#     if 'document.location' in soup.text:\n",
    "#         # need to redirect to another page\n",
    "#         redirect_url = soup.text.strip().replace('document.location = \"','').replace('\";',\"\")\n",
    "#         curr_style_url=f\"{site_root}{redirect_url}\"\n",
    "#        # print(curr_style_url)\n",
    "#         html2 = load_page(curr_style_url)\n",
    "#         soup = BeautifulSoup(html2)\n",
    "        \n",
    "    style_list = get_buildings_for_style(soup, style)\n",
    "    print(style_list)\n",
    "    buildings_list.extend(style_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webscrape():\n",
    "    '''\n",
    "    run web scraping\n",
    "    '''\n",
    "    html = load_page(main_page)\n",
    "    soup = BeautifulSoup(html)\n",
    "    style_options = soup.find('select',{'name':'MainStyle'}).find_all('option')\n",
    "    for style in style_options[1:]:\n",
    "        process_style(style.text)\n",
    "        time.sleep(5)\n",
    "        bld_df = pd.DataFrame(buildings_list)\n",
    "        bld_df.to_csv('../data/aco_buildings_'+ str(round(time.time(),0)) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_to_database(db):\n",
    "#     # recreate full links for urls\n",
    "#     bld_df['Bld_link'] =bld_df['Bld_link'].apply(lambda x: f'{site_root}{x}' )\n",
    "#     bld_df['Image'] =bld_df['Image'].apply(lambda x: f'{site_root[:-1]}{x}' )\n",
    "#     db=connect_db() #establish connection\n",
    "#     meta = MetaData(db)\n",
    "#     table = Table('points_of_interest', meta, autoload=True)\n",
    "    \n",
    "#     for ix,row in bld_df.iterrows():\n",
    "#         row_dict ={df_to_db_map[k]:v for k, v in row.items() if k in df_to_db_map.keys() and not pd.isnull(v)}\n",
    "#         new_row=db.execute(table.insert(), [ \n",
    "#             row_dict\n",
    "#         ])\n",
    "#         new_id=new_row.inserted_primary_key[0]\n",
    "#         if new_id:\n",
    "#             db.execute('''INSERT INTO architectural_styles(poi_id, style) VALUES ( {},'{}')'''.format(new_id, row['Style']))\n",
    "#             if row['Companies']:\n",
    "#                 for architect in row['Companies']:\n",
    "\n",
    "#                     db.execute('''INSERT INTO architects(poi_id, architect_name) VALUES ( {},'{}')'''.format(new_id, architect.replace(\"'\",\"''\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to database\n",
    "* ran into Error at one point because website contained duplicate entries for Moriyama and Teshima Architects for building 755.  (IntegrityError: duplicate key value violates unique constraint \"architects_pkey\" #DETAIL:  Key (poi_id, architect_name)=(755, Moriyama and Teshima Architects) already exists.\n",
    "* added check that aren't adding duplicate\n",
    "* set up dictionary with entries like: poi_dict = {}\n",
    "        poi_dict['name'] = row['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_database_ORM(session):\n",
    "    '''\n",
    "    Saves scraped data to database using SqlAlchemy ORM\n",
    "    Updates three tables: points_of_interest, archtectural_styles, architects\n",
    "    The relationship between these tables is defined in models.py, so it automatically populates the poi_id column\n",
    "    in the child tables with the poi_id of the main entry \n",
    "    '''\n",
    "    \n",
    "    for index, row in bld_df.iterrows():\n",
    "        \n",
    "        poi_dict ={df_to_db_map[k]:v for k, v in row.items() if k in df_to_db_map.keys() and not pd.isnull(v)}\n",
    "\n",
    "        poi = PointsOfInterest(**poi_dict )\n",
    "\n",
    "        # define style\n",
    "        style=ArchitecturalStyles(style=row['Style'])\n",
    "        poi.styles.append(style)\n",
    "        \n",
    "        # architects (can be multiple)\n",
    "        if row['Companies']:\n",
    "            prev_company=\"\"\n",
    "            for company in row['Companies']:\n",
    "                if company != prev_company and not 'Also see' in company:\n",
    "                    architect = Architects(architect_name= company.replace(\"'\",\"''\"))\n",
    "                    poi.architects.append(architect)\n",
    "                    prev_company=company\n",
    "        session.add(poi)\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if rerun_webscrape:\n",
    "    run_webscrape()\n",
    "    bld_df = pd.DataFrame(buildings_list)\n",
    "    bld_df.to_csv('../data/aco_buildings_'+ str(round(time.time(),0)) + '.csv')\n",
    "else:\n",
    "    # open file and save results to database\n",
    "    bld_df=pd.read_csv('../data/aco_buildings_1543192082.0.csv',index_col=0) #, converters={\"Companies\": literal_eval}) #,  converters={1:ast.literal_eval})\n",
    "    # clean up list stored in csv -- have to get python to treat as a list\n",
    "    bld_df['Companies']=bld_df['Companies'].fillna('[]')\n",
    "    bld_df.Companies = bld_df.Companies.apply(literal_eval)\n",
    "    # create full urls out of links\n",
    "    bld_df['Bld_link'] =bld_df['Bld_link'].apply(lambda x: f'{site_root}{x}' )\n",
    "    bld_df['Image'] =bld_df['Image'].apply(lambda x: f'{site_root[:-1]}{x}' )\n",
    "    \n",
    "bld_df.head()\n",
    "db=connect_db() #establish connection\n",
    "Session = sessionmaker(bind=db)\n",
    "session = Session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if populate_db:\n",
    "    save_to_database_ORM(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
