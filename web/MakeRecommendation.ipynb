{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models import connect_db, PointsOfInterest, ArchitecturalStyles, Architects,POICategories\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "import geopy.distance\n",
    "import geocoder\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium.features import DivIcon\n",
    "walknum=0\n",
    "DEBUG=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn_pandas import DataFrameMapper, CategoricalImputer\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, LabelBinarizer, Imputer, FunctionTransformer,PolynomialFeatures, OrdinalEncoder\n",
    ")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.constraint_solver import pywrapcp\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "import googlemaps\n",
    "import os\n",
    "#from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(filename='../logs/walk_stats.csv',level=logging.DEBUG)\n",
    "logging.debug(\"walknum, sim_method, optimzer, max_dist_hr, starting_lat, starting_long, duration, num_points, total_dist, avg_dist,max_dist, stop_order, num_art_stops, num_building_stops, num_plaque_stops, stop_ids, mean_similarity, max_similarity, user_profile, user_prefs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_session():\n",
    "    db=connect_db() #establish connection / creates database on first run\n",
    "    Session = sessionmaker(bind=db)\n",
    "    session = Session()\n",
    "    return db, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df['build_century'] = df['build_year_clean'].apply(lambda x: x//100*100)\n",
    "#     df['cleaned_year']=df['build_year'].apply(lambda x: clean_build_year(x))\n",
    "#     df['cleaned_year']=pd.to_numeric(df['cleaned_year'],errors='coerce',downcast='integer')\n",
    "#     df['build_decade']= df['cleaned_year'].apply(lambda x: x//10*10 )\n",
    "#     df['poi_type_simple'] = df['poi_type'].apply(lambda x: make_simple_poi(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pois_as_df():\n",
    "    \n",
    "    db, session = make_session()\n",
    "    sql='''SELECT poi.*, styl.style, pcat.category\n",
    "    FROM points_of_interest poi\n",
    "    LEFT JOIN architectural_styles styl on (styl.poi_id = poi.poi_id)\n",
    "    LEFT JOIN poi_categories pcat on (pcat.poi_id = poi.poi_id)\n",
    "    order by poi.poi_id\n",
    "    '''\n",
    "    df = pd.read_sql_query(sql, db)\n",
    "    df= add_features(df)\n",
    "    session.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_mapper = DataFrameMapper([\n",
    "   #('Date',None),\n",
    "    # drop block and address\n",
    "   # (['poi_id'], None),\n",
    "   # ('build_decade',[CategoricalImputer(replacement=\"n/a\"), LabelBinarizer()]),\n",
    "    ('build_century',[CategoricalImputer(replacement=\"n/a\"), LabelBinarizer()]),\n",
    "   #  ('category',[CategoricalImputer(replacement=\"n/a\"), LabelBinarizer()]),\n",
    "     #('architect_name',[CategoricalImputer(replacement=\"n/a\"), LabelBinarizer()]),\n",
    "     #('style',[CategoricalImputer(replacement=\"n/a\"), LabelBinarizer()]),\n",
    "     ('poi_type_simple',[CategoricalImputer(replacement=\"n/a\"), LabelBinarizer()]),\n",
    "    # ('current_use',[CategoricalImputer(replacement=\"n/a\"), LabelBinarizer()]),\n",
    "  #  (['latitude'],None),\n",
    "  #  (['longitude'],None)\n",
    "], df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(df_cols, user_sel_prefs):\n",
    "    '''\n",
    "    df_cols: list with cols of \"vectorized\" dataframe\n",
    "    user_sel_prefs: list with selected cols that interest user\n",
    "    '''\n",
    "    \n",
    "    user_prefs = np.zeros(len(df_cols))\n",
    "    \n",
    "    for pref in user_sel_prefs:\n",
    "        indx=df_cols.index(pref)\n",
    "        user_prefs[indx] = 1\n",
    "\n",
    "    df_user=pd.DataFrame(user_prefs).T\n",
    "    return df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # METHOD 2\n",
    "# # ['build_century_1700.0', 'build_century_1800.0', 'build_century_1900.0',\n",
    "# #        'build_century_2000.0', 'poi_type_simple_Art',\n",
    "# #        'poi_type_simple_Building', 'poi_type_simple_Plaque']\n",
    "\n",
    "# def get_user_profile(profile_num):\n",
    "#     '''\n",
    "#     # USER PROFILE 1 - interested in People (plaques), Entrepreneurs (32) Medicine (44), Science and Technology (52), Women (56), Sports(53) and modern buildings\n",
    "#     # USER PROFILE 2 -- interested in People (plaques 104) Explorers (33), Pioneers (46), Cemeteries (25), First Nations(35)\n",
    "# # and early buildings (0-9)\n",
    "#     # USER PROFILE 3 -- interested in Art ()\n",
    "#     '''\n",
    "#     user_prefs = np.zeros(7)\n",
    "#     if profile_num== 1:\n",
    "#         for i in [1,5]:\n",
    "#             user_prefs[i] = 1\n",
    "#     elif profile_num==2:\n",
    "#         for i in [2,6]:\n",
    "#             user_prefs[i] = 1\n",
    "#     else:\n",
    "#         for i in [4]:\n",
    "#             user_prefs[i] = 1\n",
    "#     df_user=pd.DataFrame(user_prefs).T\n",
    "#     return df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1\n",
    "# def get_user_profile(profile_num):\n",
    "#     '''\n",
    "#     # USER PROFILE 1 - interested in People (plaques), Entrepreneurs (32) Medicine (44), Science and Technology (52), Women (56), Sports(53) and modern buildings\n",
    "#     # USER PROFILE 2 -- interested in People (plaques 104) Explorers (33), Pioneers (46), Cemeteries (25), First Nations(35)\n",
    "# # and early buildings (0-9)\n",
    "#     # USER PROFILE 3 -- interested in Art ()\n",
    "#     '''\n",
    "#     user_prefs = np.zeros(105)\n",
    "#     if profile_num== 1:\n",
    "#         for i in [32, 52, 44, 56,53, 67,70,75,77, 79, 80, 83, 89, 104]:\n",
    "#             user_prefs[i] = 1\n",
    "#     elif profile_num==2:\n",
    "#         for i in [0,1,2,3,4,5,6,7,8,9,25, 33,35, 46,104]:\n",
    "#             user_prefs[i] = 1\n",
    "#     else:\n",
    "#         for i in [102]:\n",
    "#             user_prefs[i] = 1\n",
    "#     df_user=pd.DataFrame(user_prefs).T#, columns=df_features.columns)\n",
    "# #     df_user.columns = df_features.columns\n",
    "# #     #df_user=pd.DataFrame.from_records(user_prefs,)\n",
    "# #     df_user.head()\n",
    "#     return df_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_similarity(df_features, df_user,  df_poi, sim_method=cosine_similarity):\n",
    "    '''\n",
    "    INPUTS: \"vectorized\" dataframes of POIS and User\n",
    "    sim_method:\n",
    "        * cosine_similarity=\n",
    "        * spatial = \n",
    "        * hamming\n",
    "    RETURNS: dataframe of Points of Interest sorted from highest to lowest similarity rating to the user prefs\n",
    "    '''\n",
    "    df_poi['sim_rating'] = 0\n",
    "    if sim_method =='cosine_similarity':\n",
    "        print('cosine_similarity')\n",
    "        cosine_sim = cosine_similarity(df_features,df_user)\n",
    "        user_matches = pd.DataFrame(cosine_sim, columns=['user_match']) # convert to df for ease\n",
    "        user_matches.sort_values('user_match', ascending=False, inplace=True) # sort from best to worst matches\n",
    "       # for ix,row in user_matches.iloc[0:20,:].iterrows():\n",
    "        for ix,row in user_matches.iterrows():\n",
    "            # now find matches close to target of interest - ix is row in dataframe that matches to user match\n",
    "            df_poi.loc[ix,'sim_rating'] = row.user_match\n",
    "    else:\n",
    "        \n",
    "        # spatial method requires numpy arrays\n",
    "        np_features = df_features.as_matrix()\n",
    "        U=df_user.as_matrix()\n",
    "        weight_of_importance=[0.05,0.05,0.05,0.05,.27,.26,.27]\n",
    "        site_prefs=[]\n",
    "        for i in range(0,len(np_features)):\n",
    "            np_features[i,:]\n",
    "            if sim_method== 'spatial':\n",
    "               # print('spatial')\n",
    "                result = spatial.distance.cosine(np_features[i,:], U, weight_of_importance)\n",
    "            else:\n",
    "                #print('hamming')\n",
    "                result = spatial.distance.hamming(np_features[i,:], U)\n",
    "            res_dict = {'ix': i, 'dist': result}\n",
    "            site_prefs.append(res_dict)\n",
    "        # convert similarity rating for each POI to a df\n",
    "        df_site_prefs = pd.DataFrame(site_prefs)\n",
    "        df_site_prefs.sort_values('dist', ascending=False, inplace=True)\n",
    "        \n",
    "        for ix,row in df_site_prefs.iterrows():\n",
    "            # now find matches close to target of interest\n",
    "            df_poi.loc[ix,'sim_rating'] = row.dist\n",
    "\n",
    "\n",
    "    df_poi.sort_values('sim_rating', inplace=True, ascending=False)\n",
    "    return df_poi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_points_in_area(df, lat, long, num_points, max_distance):\n",
    "    '''\n",
    "    Loop through POI dataframe that has already been sorted by similiarty to user prefs (from highest to lowest match)\n",
    "    find distance for each POI from starting point in meters\n",
    "    Check if is within the desired radius of the starting point to be a candidate stop\n",
    "    --> if yes, collect it in the avail_points list and increment the count of found stops\n",
    "    We have a few POIs with the exact same coordinates (sometimes due to duplicates, but also because some buildings may have multiple artworks)\n",
    "    --> this causes problems for google maps plotting of stops and also a fairly pointless walk with a bunch of stops in the same area\n",
    "    --> for now, only include the first POI at a given set of coordinates.  Use sets to make sure our coordinates are unique\n",
    "    due to some dirty data, have a few POIs with the same coordinates so skip repeats )\n",
    "    Once we have found the desired number of stops, exit\n",
    "    \n",
    "    RETURNS: filtered dataframe of candidate stops with ~length of num_points\n",
    "    \n",
    "    ## TODO: colllect all possible stops and then cluster?\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    avail_points = []\n",
    "    found_points =0\n",
    "    prev_coord = (0,0) # sometimes have two points at same lat/long -- don't count as an extra stop\n",
    "    prev_coords = set({})\n",
    "    for ix, row in df.iterrows():\n",
    "\n",
    "        curr_pt = geopy.distance.geodesic((row['latitude'], row['longitude']), (lat, long)).meters\n",
    "        \n",
    "        if curr_pt<= max_distance:\n",
    "            c=(row['latitude'], row['longitude'])\n",
    "            coord = set({c})\n",
    "            if prev_coords.issuperset(coord) == False:\n",
    "                # only include POIs whose coordinates are not already in our list of stops\n",
    "                prev_coords.add(c)    \n",
    "                my_dict={}\n",
    "                my_dict =row.to_dict()\n",
    "                my_dict['dist_start'] = curr_pt\n",
    "                avail_points.append(my_dict)\n",
    "                found_points +=1\n",
    "                if found_points > num_points:\n",
    "                    break\n",
    "    df_2 = pd.DataFrame(avail_points)\n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_points_in_area(df, lat, long, num_points, max_distance):\n",
    "#     '''\n",
    "#     Loop through POI dataframe that has already been sorted by similiarty to user prefs (from highest to lowest match)\n",
    "#     find distance for each POI from starting point in meters\n",
    "#     Check if is within the desired radius of the starting point to be a candidate stop\n",
    "#     --> if yes, collect it in the avail_points list and increment the count of found stops\n",
    "#     (due to some dirty data, have a few POIs with the same coordinates so make sure only count that coordinates once)\n",
    "#     Once we have found the desired number of stops, exit\n",
    "    \n",
    "#     RETURNS: filtered dataframe of candidate stops with ~length of num_points\n",
    "    \n",
    "#     ## TODO: colllect all possible stops and then cluster?\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     avail_points = []\n",
    "#     found_points =0\n",
    "#     prev_coord = (0,0) # sometimes have two points at same lat/long -- don't count as an extra stop\n",
    "    \n",
    "#     for ix, row in df.iterrows():\n",
    "\n",
    "#         curr_pt = geopy.distance.geodesic((row['latitude'], row['longitude']), (lat, long)).meters\n",
    "        \n",
    "#         if curr_pt<= max_distance:\n",
    "#             my_dict={}\n",
    "#             my_dict =row.to_dict()\n",
    "#             my_dict['dist_start'] = curr_pt\n",
    "#             avail_points.append(my_dict)\n",
    "#             if (row['latitude'], row['longitude']) !=prev_coord:\n",
    "#                 found_points +=1\n",
    "#             prev_coord = (row['latitude'], row['longitude'])\n",
    "#             if found_points > num_points:\n",
    "#                 break\n",
    "#     df_2 = pd.DataFrame(avail_points)\n",
    "#     return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize map with a default lat and long\n",
    "import folium\n",
    "def plot_stops(starting_lat, starting_long, df):\n",
    "    map_clusters = folium.Map(location=[43.67146, -79.37515], zoom_start=11)\n",
    "    folium.CircleMarker(\n",
    "        [starting_lat, starting_long],\n",
    "        radius=5,\n",
    "        color='red',\n",
    "         fill=True,\n",
    "           fill_color='#3186cc',\n",
    "           fill_opacity=0.7).add_to(map_clusters)\n",
    "\n",
    "\n",
    "\n",
    "    # loop through dataframe\n",
    "    for lat, lng, name, address in zip(df['latitude'], df['longitude'],  df['name'],df['address']):\n",
    "       label = '{} {}'.format(name, address)\n",
    "       label = folium.Popup(label, parse_html=True)\n",
    "       folium.CircleMarker(\n",
    "           [lat, lng],\n",
    "           radius=5,\n",
    "           popup=label,\n",
    "           color='blue',\n",
    "           fill=True,\n",
    "           fill_color='#3186cc',\n",
    "           fill_opacity=0.7).add_to(map_clusters)\n",
    "\n",
    "    return map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENETIC ALGORITHM TO PLOT POINTS\n",
    "* borrowed and slightly adapted from https://github.com/ZWMiller/PythonProjects/blob/master/genetic_algorithms/evolutionary_algorithm_traveling_salesman.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cluster points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_of_stop_coords(df,starting_lat, starting_long, key_to_use='poi_id'):\n",
    "    '''\n",
    "    create dictionary of stops with lat/long coords\n",
    "    first stop is the starting point\n",
    "    '''\n",
    "   # print(f'starting point ({starting_lat}, {starting_long})')\n",
    "    walk_stops = {}\n",
    "    walk_stops[0] = (starting_lat, starting_long)\n",
    "    for ix,row in df.iterrows():\n",
    "        \n",
    "        if key_to_use=='poi_id':\n",
    "            walk_stops[row['poi_id']] = (row['latitude'], row['longitude'])\n",
    "        else:\n",
    "            walk_stops[ix+1] = (row['latitude'], row['longitude'])\n",
    "        \n",
    "    return walk_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_guess(walk_stops):\n",
    "    \"\"\"\n",
    "    Creates a possible path between all cities, returning to the original.\n",
    "    Point 0 is our starting point and must stay as our starting point\n",
    "    Input: List of City IDs\n",
    "    \"\"\"\n",
    "    guess = copy(walk_stops)\n",
    "   # print(f\"before shuffle {guess}\")\n",
    "    start = guess.pop(0)# save our starting point and remove from dict\n",
    "    np.random.shuffle(guess)\n",
    "   # print(f\"after shuffle {guess}\")\n",
    "   # guess[0] = start\n",
    "    guess.insert(0,start)\n",
    "    #guess.append(guess[0])\n",
    "    return list(guess)\n",
    "\n",
    "#print(create_guess(list(walk_stops.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_generation(points, population=100):\n",
    "    \"\"\"\n",
    "    Makes a list of guessed point orders given a list of point IDs.\n",
    "    Input:\n",
    "    points: list of point ids\n",
    "    population: how many guesses to make\n",
    "    \"\"\"\n",
    "    generation = [create_guess(points) for _ in range(population)]\n",
    "    return generation\n",
    "\n",
    "# test_generation = create_generation(list(walk_stops.keys()), population=10)\n",
    "# for gen in test_generation:\n",
    "#     print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_time_between_points(point_1, point_2):\n",
    "    '''\n",
    "    pass in coords for 2 points\n",
    "    calculate distance between them in meters and then estimate walking time\n",
    "    '''\n",
    "    # typical walkign speed is 1.4m/sec\n",
    "    speed = 1.4\n",
    "    #find dist between 2 points\n",
    "    dist = geopy.distance.geodesic(point_1, point_2).meters\n",
    "    # return guess speed in seconds\n",
    "    return dist/speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_score(guess, walk_stops):\n",
    "    \"\"\"\n",
    "    Loops through the points in the guesses order and calculates\n",
    "    how much distance the path would take to complete a loop.\n",
    "    Lower is better.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    for ix, point_id in enumerate(guess[:-1]):\n",
    "        score += travel_time_between_points(walk_stops[point_id], walk_stops[guess[ix+1]])\n",
    "    return score\n",
    "\n",
    "def check_fitness(guesses, walk_stops):\n",
    "    \"\"\"\n",
    "    Goes through every guess and calculates the fitness score. \n",
    "    Returns a list of tuples: (guess, fitness_score)\n",
    "    \"\"\"\n",
    "    fitness_indicator = []\n",
    "    for guess in guesses:\n",
    "        fitness_indicator.append((guess, fitness_score(guess, walk_stops)))\n",
    "    return fitness_indicator\n",
    "\n",
    "#print(check_fitness(test_generation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breeders_from_generation(guesses, walk_stops, take_best_N=10, take_random_N=5, verbose=False, mutation_rate=0.1):\n",
    "    \"\"\"\n",
    "    This sets up the breeding group for the next generation. You have\n",
    "    to be very careful how many breeders you take, otherwise your\n",
    "    population can explode. These two, plus the \"number of children per couple\"\n",
    "    in the make_children function must be tuned to avoid exponential growth or decline!\n",
    "    \"\"\"\n",
    "    # First, get the top guesses from last time\n",
    "    fit_scores = check_fitness(guesses, walk_stops)\n",
    "    sorted_guesses = sorted(fit_scores, key=lambda x: x[1]) # sorts so lowest is first, which we want\n",
    "    new_generation = [x[0] for x in sorted_guesses[:take_best_N]] # takes top 5\n",
    "    best_guess = new_generation[0] # best guess is the best score\n",
    "    \n",
    "    if verbose:\n",
    "        # If we want to see what the best current guess is!\n",
    "        print(best_guess)\n",
    "    \n",
    "    # Second, get some random ones for genetic diversity\n",
    "    for _ in range(take_random_N):\n",
    "        ix = np.random.randint(len(guesses))\n",
    "        new_generation.append(guesses[ix])\n",
    "        \n",
    "    # No mutations here since the order really matters.\n",
    "    # If we wanted to, we could add a \"swapping\" mutation,\n",
    "    # but in practice it doesn't seem to be necessary\n",
    "    \n",
    "    np.random.shuffle(new_generation)\n",
    "    return new_generation, best_guess\n",
    "\n",
    "def make_child(parent1, parent2):\n",
    "    \"\"\" \n",
    "    Take some values from parent 1 and hold them in place, then merge in values\n",
    "    from parent2, filling in from left to right with cities that aren't already in \n",
    "    the child. \n",
    "    \"\"\"\n",
    "    list_of_ids_for_parent1 = list(np.random.choice(parent1, replace=False, size=len(parent1)//2))\n",
    "   # print(list_of_ids_for_parent1)\n",
    "    child = [-99 for _ in parent1] # fill with placeholders so now all -99 values can be replaced with genes from parent 2\n",
    "    \n",
    "    for ix in range(0, len(list_of_ids_for_parent1)):\n",
    "        child[ix] = parent1[ix]\n",
    "\n",
    "    for ix, gene in enumerate(child):\n",
    " \n",
    "        if gene == -99:\n",
    "            for gene2 in parent2:\n",
    "                if gene2 not in child:\n",
    "                    child[ix] = gene2\n",
    "                    break\n",
    "    #child[-1] = child[0]\n",
    "    return child\n",
    "\n",
    "def make_children(old_generation, children_per_couple=1):\n",
    "    \"\"\"\n",
    "    Pairs parents together, and makes children for each pair. \n",
    "    If there are an odd number of parent possibilities, one \n",
    "    will be left out. \n",
    "    \n",
    "    Pairing happens by pairing the first and last entries. \n",
    "    Then the second and second from last, and so on.\n",
    "    \"\"\"\n",
    "  #  print(old_generation)\n",
    "    mid_point = len(old_generation)//2\n",
    "#    print(mid_point)\n",
    "    next_generation = [] \n",
    "    \n",
    "    for ix, parent in enumerate(old_generation[:mid_point]):\n",
    "        for _ in range(children_per_couple):\n",
    "            next_generation.append(make_child(parent, old_generation[-ix-1]))\n",
    "   # print(next_generation)\n",
    "    return next_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_to_solve(current_generation, max_generations, take_best_N, take_random_N,\n",
    "                    mutation_rate, children_per_couple, print_every_n_generations, walk_stops, verbose=False):\n",
    "    \"\"\"\n",
    "    Takes in a generation of guesses then evolves them over time using our breeding rules.\n",
    "    Continue this for \"max_generations\" times.\n",
    "    Inputs:\n",
    "    current_generation: The first generation of guesses\n",
    "    max_generations: how many generations to complete\n",
    "    take_best_N: how many of the top performers get selected to breed\n",
    "    take_random_N: how many random guesses get brought in to keep genetic diversity\n",
    "    mutation_rate: How often to mutate (currently unused)\n",
    "    children_per_couple: how many children per breeding pair\n",
    "    print_every_n_geneartions: how often to print in verbose mode\n",
    "    verbose: Show printouts of progress\n",
    "    Returns:\n",
    "    fitness_tracking: a list of the fitness score at each generations\n",
    "    best_guess: the best_guess at the end of evolution\n",
    "    \"\"\"\n",
    "    fitness_tracking = []\n",
    "    for i in range(max_generations):\n",
    "        if verbose and not i % print_every_n_generations and i > 0:\n",
    "            print(\"Generation %i: \"%i, end='')\n",
    "            print(len(current_generation))\n",
    "            print(\"Current Best Score: \", fitness_tracking[-1])\n",
    "            is_verbose = True\n",
    "        else:\n",
    "            is_verbose = False\n",
    "        breeders, best_guess = get_breeders_from_generation(current_generation, walk_stops, \n",
    "                                                            take_best_N=take_best_N, take_random_N=take_random_N, \n",
    "                                                            verbose=is_verbose, mutation_rate=mutation_rate)\n",
    "        fitness_tracking.append(fitness_score(best_guess, walk_stops))\n",
    "        current_generation = make_children(breeders, children_per_couple=children_per_couple)\n",
    "    \n",
    "    return fitness_tracking, best_guess\n",
    "\n",
    "#current_generation = create_generation(list(walk_stops.keys()),population=500)\n",
    "# for gen in current_generation:\n",
    "#     print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stop_order_to_df(df, order_guess, key_to_use='poi_id'):\n",
    "    df['order'] =0\n",
    "    cnt = 1\n",
    "    for ix in order_guess[1:]:\n",
    "        if key_to_use=='poi_id':\n",
    "            index = df[df_filtered['poi_id'] ==ix].index\n",
    "        else:\n",
    "            index = ix-1\n",
    "        df.iloc[index,-1]=cnt\n",
    "        cnt +=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_guess(city_coordinates, guess, guess_in_title=True):\n",
    "    \"\"\"\n",
    "    Takes the coordinates of the cities and the guessed path and\n",
    "    makes a plot connecting the cities in the guessed order\n",
    "    Input:\n",
    "    city_coordinate: dictionary of city id, (x,y)\n",
    "    guess: list of ids in order\n",
    "    \"\"\"\n",
    "    plot_cities(city_coordinates, guess=guess)\n",
    "    for ix, current_city in enumerate(guess[:-1]):\n",
    "        x = [city_coordinates[guess[ix]][0],city_coordinates[guess[ix+1]][0]]\n",
    "        y = [city_coordinates[guess[ix]][1],city_coordinates[guess[ix+1]][1]]\n",
    "        plt.plot(x,y,'c--',lw=1)\n",
    "    plt.scatter(city_coordinates[guess[0]][0],city_coordinates[guess[0]][1], marker='x', c='b')   \n",
    "    if guess_in_title:\n",
    "        plt.title(\"Current Guess: [%s]\"%(','.join([str(x) for x in guess])))\n",
    "    else:\n",
    "        print(\"Current Guess: [%s]\"%(','.join([str(x) for x in guess])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cities(city_coordinates, annotate=True, guess=None):\n",
    "    \"\"\"\n",
    "    Makes a plot of all cities.\n",
    "    Input: city_coordinates; dictionary of all cities and their coordinates in (x,y) format\n",
    "    \"\"\"\n",
    "    names = []\n",
    "    x = []\n",
    "    y = []\n",
    "    plt.figure(dpi=250, figsize=(20,20))\n",
    "    for key in list(city_coordinates.keys()):\n",
    "        names.append(key)\n",
    "        x.append(city_coordinates[key][0])\n",
    "        y.append(city_coordinates[key][1])\n",
    "        if annotate:\n",
    "            if guess:\n",
    "                plt.annotate(guess.index(key), xy=(city_coordinates[key][0], city_coordinates[key][1]), xytext=(20, -20),\n",
    "                            textcoords='offset points', ha='right', va='bottom',\n",
    "                            bbox=dict(boxstyle='round,pad=0.5', fc='w', alpha=0.5),\n",
    "                            arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "            else:\n",
    "                plt.annotate(ix, xy=(city_coordinates[key][0], city_coordinates[key][1]), xytext=(20, -20),\n",
    "                            textcoords='offset points', ha='right', va='bottom',\n",
    "                            bbox=dict(boxstyle='round,pad=0.5', fc='w', alpha=0.5),\n",
    "                            arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "    plt.scatter(x,y,c='r',marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fitness_tracking_plot(fitness_tracking):\n",
    "    \"\"\"\n",
    "    Given a list of fitness scores, plot it versus the generation number\n",
    "    \"\"\"\n",
    "    plt.figure(dpi=150)\n",
    "    plt.plot(range(len(fitness_tracking)), fitness_tracking)\n",
    "    plt.ylabel(\"Fitness Score\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.title(\"Fitness Evolution\");\n",
    "\n",
    "#make_fitness_tracking_plot(fitness_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stops_with_order(df, starting_lat, starting_long):\n",
    "    map_clusters = folium.Map(location=[43.67146, -79.37515], zoom_start=11)\n",
    "    folium.CircleMarker(\n",
    "        [starting_lat, starting_long],\n",
    "        radius=5,\n",
    "        color='red',\n",
    "         fill=True,\n",
    "           fill_color='#3186cc',\n",
    "           fill_opacity=0.7).add_to(map_clusters)\n",
    "\n",
    "\n",
    "\n",
    "    # loop through dataframe\n",
    "    for lat, lng, name, address,order in zip(df['latitude'], df['longitude'],  df['name'],df['address'], df['order']):\n",
    "        label = '{} {}'.format(name, address)\n",
    "        label = folium.Popup(label, parse_html=True)\n",
    "        folium.map.Marker(\n",
    "        [lat, lng],\n",
    "        icon=DivIcon(\n",
    "            icon_size=(150,36),\n",
    "            icon_anchor=(0,0),\n",
    "           # html='<b><div style=\"color:red,font-size: 10pt\">{}</div></b>'.format(order),\n",
    "            html='<b><div style=\"color:red\">{}</div></b>'.format(order),\n",
    "            )\n",
    "        ).add_to(map_clusters)\n",
    "\n",
    "    return map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_route(df, starting_lat, starting_long, method='genetic'):\n",
    "    '''\n",
    "    Possible methods: genetic or google optimisation tools\n",
    "    '''\n",
    "    walk_stops = get_dict_of_stop_coords(df, starting_lat, starting_long)\n",
    "    if method == 'genetic':\n",
    "        current_generation = create_generation(list(walk_stops.keys()),population=500)\n",
    "        fitness_tracking, best_guess = evolve_to_solve(current_generation, 100, 150, 70, 0.5, 3, 5, walk_stops, verbose=True)\n",
    "        plot_guess(walk_stops, best_guess)\n",
    "        # add order to df.\n",
    "        df=add_stop_order_to_df(df, best_guess)\n",
    "        make_fitness_tracking_plot(fitness_tracking)\n",
    "        map_stops = plot_stops_with_order(df, starting_lat, starting_long)\n",
    "        total_dist=0\n",
    "    else:\n",
    "        #method='google'\n",
    "        walk_stops = get_dict_of_stop_coords(df, starting_lat, starting_long, key_to_use='count')\n",
    "        dist_matrix=make_dist_matrix(len(walk_stops))\n",
    "        order_guess, total_dist=create_routing_model(walk_stops,dist_matrix)\n",
    "\n",
    "        df=add_stop_order_to_df(df, order_guess,key_to_use='count')\n",
    "        map_stops = plot_stops_with_order(df, starting_lat, starting_long)\n",
    "    return map_stops, order_guess, df, walk_stops, total_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with Google OR Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_key():\n",
    "    load_dotenv(find_dotenv())\n",
    "    # load environment variables\n",
    "    SECRET_KEY = os.getenv(\"GOOGLE_KEY\")\n",
    "    gmaps = googlemaps.Client(key=SECRET_KEY)\n",
    "    return gmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance callback\n",
    "def create_distance_callback(dist_matrix):\n",
    "    # Create a callback to calculate distances between cities.\n",
    "\n",
    "    def distance_callback(from_node, to_node):\n",
    "        # return int(dist_matrix[from_node][to_node])\n",
    "        #print(dist_matrix[from_node][to_node])\n",
    "        return dist_matrix[from_node][to_node]\n",
    "\n",
    "\n",
    "    return distance_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dist_matrix(num_rows):\n",
    "    #my_dist_matrix = np.zeros((len(walk_stops), len(walk_stops)))\n",
    "    dist_matrix = np.zeros((num_rows,num_rows))\n",
    "    return dist_matrix\n",
    "#dist_matrix = gmaps.distance_matrix(walk_stops.values(),walk_stops.values())\n",
    "#my_dist_matrix[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_distance(x1, y1, x2, y2):\n",
    "    # Euclidean distance between points.\n",
    "    dist = math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_matrix(locations):\n",
    "    # Create the distance matrix.\n",
    "    gmaps = get_google_key()\n",
    "    size = len(locations)\n",
    "    dist_matrix = {}\n",
    "   # dist_matrix = pickle.load(open(\"C:/Users/blahjays/Documents/GitHubCode/Personal_Public/TorontoWalks/torontowalks/dist_matrix.pkl\",\"rb\"))\n",
    "\n",
    "    for from_node in locations.keys():\n",
    "        dist_matrix[from_node] = {}\n",
    "        for to_node in locations.keys():\n",
    "            x1 = locations.get(from_node)[0]\n",
    "            y1 = locations.get(from_node)[1]\n",
    "            x2 = locations.get(to_node)[0]\n",
    "            y2 = locations.get(to_node)[1]\n",
    "            #print(x1,y1, x2, y2)\n",
    "           # dist_matrix[from_node][to_node] = euclid_distance(x1, y1, x2, y2)\n",
    "            #dist_matrix[from_node][to_node]  = gmaps.distance_matrix((x1,y1), (x2,y2), mode='walking')[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]\n",
    "            dist_matrix[from_node][to_node]  = geopy.distance.geodesic((x1,y1), (x2,y2)).meters\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist_matrix\n",
    "#https://developers.google.com/optimization/routing/tsp\n",
    "def create_routing_model(walk_stops, dist_matrix ):\n",
    "    tsp_size = len(walk_stops)\n",
    "    num_routes = 1\n",
    "    depot = 0\n",
    "    best_guess=[]\n",
    "\n",
    "    # Create routing model\n",
    "    if tsp_size > 0:\n",
    "        routing = pywrapcp.RoutingModel(tsp_size, num_routes, depot)\n",
    "        search_parameters = pywrapcp.RoutingModel.DefaultSearchParameters()\n",
    "        # Create the distance callback.\n",
    "        dist_matrix=create_distance_matrix(walk_stops)\n",
    "        dist_callback = create_distance_callback(dist_matrix)\n",
    "        #print(dist_matrix)\n",
    "        routing.SetArcCostEvaluatorOfAllVehicles(dist_callback)\n",
    "        # Solve the problem.\n",
    "        assignment = routing.SolveWithParameters(search_parameters)\n",
    "        if assignment:\n",
    "            # Solution distance.\n",
    "            print (\"Total distance: \" + str(assignment.ObjectiveValue()) + \" meters\\n\")\n",
    "            total_dist = assignment.ObjectiveValue()\n",
    "           # logging.debug(\"Total distance: \" + str(assignment.ObjectiveValue()) + \" meters\\n\")\n",
    "            # Display the solution.\n",
    "            # Only one route here; otherwise iterate from 0 to routing.vehicles() - 1\n",
    "            route_number = 0\n",
    "            index = routing.Start(route_number) # Index of the variable for the starting node.\n",
    "            route = ''\n",
    "            while not routing.IsEnd(index):\n",
    "                # Convert variable indices to node indices in the displayed route.\n",
    "                print(routing.IndexToNode(index))\n",
    "                best_guess.append(routing.IndexToNode(index))\n",
    "                route += str(walk_stops[routing.IndexToNode(index)]) + ' -> '\n",
    "                index = assignment.Value(routing.NextVar(index))\n",
    "            route += str(walk_stops[routing.IndexToNode(index)])\n",
    "            print (\"Route:\\n\\n\" + route)\n",
    "            #logging.debug(\"Route:\\n\\n\" + route)\n",
    "        else:\n",
    "            print( 'No solution found.')\n",
    "            #logging.debug(\"No solution found\")\n",
    "    else:\n",
    "        print ('Specify an instance greater than 0.')\n",
    "    return best_guess, total_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RouteTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_points = [(43.647273,-79.386560),(43.668697,-79.394173),(43.668752,-79.305300),(43.683117, -79.418790)]\n",
    "durations = [1]\n",
    "pts_per_hour=[12]\n",
    "max_dist_per_hour=[500, 1000]\n",
    "user_profiles = [1,2,3]\n",
    "similarity_methods=['cosine_similarity','spatial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walknum=0\n",
    "# store in log\n",
    "\n",
    "#similarity_method ='spatial' # 'co-sine'\n",
    "optimizer = 'or'\n",
    "for similarity_method in similarity_methods:\n",
    "    for pt in starting_points:\n",
    "        for dur in durations:\n",
    "            for maxdist in max_dist_per_hour:\n",
    "                for pph in pts_per_hour:\n",
    "                    for u in user_profiles:\n",
    "                        num_points = dur * pph\n",
    "                        max_distance=dur * maxdist\n",
    "\n",
    "                        df_user = get_user_profile(u)\n",
    "                        df_poi = get_pois_as_df()\n",
    "                        df_features=df_poi.copy()\n",
    "                        poi_mapper.fit(df_features)\n",
    "                        df_features= poi_mapper.transform(df_features)\n",
    "                        df_poi=find_similarity(df_features, df_user, df_poi,sim_method=similarity_method)\n",
    "                        df_filtered = find_points_in_area(df_poi, pt[0], pt[1], num_points, max_distance)\n",
    "                        map_stops, guess, df_filtered, walk_stops, total_dist=find_optimal_route(df_filtered,pt[0], pt[1], method='google')\n",
    "\n",
    "                        stops_ordered = []\n",
    "                        for stop in guess:\n",
    "                            stops_ordered.append(walk_stops[stop])\n",
    "                        df_filtered.sort_values(\"order\", inplace=True, ascending=True)\n",
    "                        \n",
    "                        # get info about the generated walkd\n",
    "                        num_art=len(df_filtered[df_filtered['poi_type_simple']=='Art'])\n",
    "                        num_building = len(df_filtered[df_filtered['poi_type_simple']=='Building'])\n",
    "                        num_plaque = len(df_filtered[df_filtered['poi_type_simple']=='Plaque'])\n",
    "\n",
    "                        stops = str(df_filtered['poi_id'].values)\n",
    "\n",
    "                        guess2=map(str,guess) \n",
    "                        guess2='-'.join(guess2)\n",
    "                        walknum += 1\n",
    "                        logging.debug(f\"{walknum}, {similarity_method}, {optimizer}, {maxdist},{pt[0]}, {pt[1]}, {dur},\\\n",
    "                                      {num_points}, {total_dist}, {total_dist/num_points}, {0}, {guess2}, {num_art}, {num_building}, \\\n",
    "                                      {num_plaque}, {stops},{df_filtered['sim_rating'].mean()}, \\\n",
    "                                        {df_filtered['sim_rating'].max()}, {u}, simplified prefs \")\n",
    "                        df_filtered.to_csv(f'../logs/walk_{walknum}.csv')\n",
    "                        #df_user.to_csv(f'../logs/userprefs_{walknum}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1 walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# king/simco\n",
    "starting_lat =43.647273\n",
    "starting_long=-79.386560\n",
    "# Avenue/bloor\n",
    "# starting_lat =43.668697\n",
    "# starting_long=-79.394173\n",
    "# #lakeshort / woodbine\n",
    "# starting_lat =43.668752\n",
    "# starting_long=-79.305300\n",
    "# #st clair / bathhurst\n",
    "# starting_lat =43.683117\n",
    "# starting_long=-79.418790\n",
    "\n",
    "# walk_duration = 1 # in hours\n",
    "# num_points = 12\n",
    "# max_distance = 1000 # meters\n",
    "# num_pois_visit = 20\n",
    "duration = .5\n",
    "pts_per_hour = 12\n",
    "max_dist_per_hour = 1000 # meters\n",
    "num_points = duration * pts_per_hour\n",
    "max_distance=duration * max_dist_per_hour\n",
    "#user_profile=3\n",
    "user_interests = ['build_century_1700.0', 'poi_type_simple_Plaque']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <script>L_PREFER_CANVAS=false; L_NO_TOUCH=false; L_DISABLE_3D=false;</script>
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.2.0/dist/leaflet.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.2.0/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawgit.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
    <style>#map_7bc78280a036424b88baeecf9c8eb27c {
        position: relative;
        width: 100.0%;
        height: 100.0%;
        left: 0.0%;
        top: 0.0%;
        }
    </style>
</head>
<body>    
    
    <div class="folium-map" id="map_7bc78280a036424b88baeecf9c8eb27c" ></div>
</body>
<script>    
    
    
        var bounds = null;
    

    var map_7bc78280a036424b88baeecf9c8eb27c = L.map(
        'map_7bc78280a036424b88baeecf9c8eb27c', {
        center: [43.67146, -79.37515],
        zoom: 11,
        maxBounds: bounds,
        layers: [],
        worldCopyJump: false,
        crs: L.CRS.EPSG3857,
        zoomControl: true,
        });

    
    
    var tile_layer_baf92984f1ab475c8656ba4bbc58d4b3 = L.tileLayer(
        'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png',
        {
        "attribution": null,
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "subdomains": "abc"
}).addTo(map_7bc78280a036424b88baeecf9c8eb27c);
    
            var circle_marker_c95609d976ce44ae941d18b84e89b494 = L.circleMarker(
                [43.647273, -79.38656],
                {
  "bubblingMouseEvents": true,
  "color": "red",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var circle_marker_d5b2f11eec6a42778cacc438591bd283 = L.circleMarker(
                [43.64858, -79.39229],
                {
  "bubblingMouseEvents": true,
  "color": "blue",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var popup_92e916c771d84ee6b8c7b859b9e0c4c7 = L.popup({maxWidth: '300'
            
            });

            
                var html_97ba180ad8ad4ef7abd76101fbfdfa24 = $('<div id="html_97ba180ad8ad4ef7abd76101fbfdfa24" style="width: 100.0%; height: 100.0%;">269-277 Richmond Street West 269-277 Richmond Street West Entertainment District Toronto, ON</div>')[0];
                popup_92e916c771d84ee6b8c7b859b9e0c4c7.setContent(html_97ba180ad8ad4ef7abd76101fbfdfa24);
            

            circle_marker_d5b2f11eec6a42778cacc438591bd283.bindPopup(popup_92e916c771d84ee6b8c7b859b9e0c4c7)
            ;

            
        
    
            var circle_marker_a225ff3abecc4c08a6494bc94888f16a = L.circleMarker(
                [43.64745, -79.3876],
                {
  "bubblingMouseEvents": true,
  "color": "blue",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var popup_f28007b0e315433680b24a8cd439a256 = L.popup({maxWidth: '300'
            
            });

            
                var html_33bb1144afe5410883eafe9a1f43118e = $('<div id="html_33bb1144afe5410883eafe9a1f43118e" style="width: 100.0%; height: 100.0%;">Royal Alexandra Theatre 260 King Street West Entertainment District Toronto, ON</div>')[0];
                popup_f28007b0e315433680b24a8cd439a256.setContent(html_33bb1144afe5410883eafe9a1f43118e);
            

            circle_marker_a225ff3abecc4c08a6494bc94888f16a.bindPopup(popup_f28007b0e315433680b24a8cd439a256)
            ;

            
        
    
            var circle_marker_43cf01b6c51a4d9193b134d03118321f = L.circleMarker(
                [43.65169, -79.38753],
                {
  "bubblingMouseEvents": true,
  "color": "blue",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var popup_51f2ab0e583d4571b9d2cea8f691d1d5 = L.popup({maxWidth: '300'
            
            });

            
                var html_1b75940e24ff4e8aaca2182475b385fc = $('<div id="html_1b75940e24ff4e8aaca2182475b385fc" style="width: 100.0%; height: 100.0%;">Canada Life Building 330 University Avenue Downtown Toronto, ON</div>')[0];
                popup_51f2ab0e583d4571b9d2cea8f691d1d5.setContent(html_1b75940e24ff4e8aaca2182475b385fc);
            

            circle_marker_43cf01b6c51a4d9193b134d03118321f.bindPopup(popup_51f2ab0e583d4571b9d2cea8f691d1d5)
            ;

            
        
    
            var circle_marker_c7b214864a2b4c7eba004b03bfbe8aaa = L.circleMarker(
                [43.64584, -79.39065],
                {
  "bubblingMouseEvents": true,
  "color": "blue",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var popup_2e4c8605fc6d477faf510c44d41c6a8f = L.popup({maxWidth: '300'
            
            });

            
                var html_794e2db3b42048ea92a7c6b40532df0e = $('<div id="html_794e2db3b42048ea92a7c6b40532df0e" style="width: 100.0%; height: 100.0%;">John B. Reid House 24 Mercer Street Entertainment District Toronto, ON</div>')[0];
                popup_2e4c8605fc6d477faf510c44d41c6a8f.setContent(html_794e2db3b42048ea92a7c6b40532df0e);
            

            circle_marker_c7b214864a2b4c7eba004b03bfbe8aaa.bindPopup(popup_2e4c8605fc6d477faf510c44d41c6a8f)
            ;

            
        
    
            var circle_marker_b50ab991d9cc4c9c80cb947395f48378 = L.circleMarker(
                [43.64757, -79.38684],
                {
  "bubblingMouseEvents": true,
  "color": "blue",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var popup_d677724f14a3437896750b09c9ede1a6 = L.popup({maxWidth: '300'
            
            });

            
                var html_5684543c73ec444abcb520bb1ecad964 = $('<div id="html_5684543c73ec444abcb520bb1ecad964" style="width: 100.0%; height: 100.0%;">Canadian General Electric Building 214 King Street West Entertainment District Toronto, ON</div>')[0];
                popup_d677724f14a3437896750b09c9ede1a6.setContent(html_5684543c73ec444abcb520bb1ecad964);
            

            circle_marker_b50ab991d9cc4c9c80cb947395f48378.bindPopup(popup_d677724f14a3437896750b09c9ede1a6)
            ;

            
        
    
            var circle_marker_dc87f79a75144a45aa5bc4add6f89bcb = L.circleMarker(
                [43.6486892700195, -79.3854370117188],
                {
  "bubblingMouseEvents": true,
  "color": "blue",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var popup_52ec038df2004937b6b5d95c3c365536 = L.popup({maxWidth: '300'
            
            });

            
                var html_589892798e954698ac27e67daf51511a = $('<div id="html_589892798e954698ac27e67daf51511a" style="width: 100.0%; height: 100.0%;">National Cash Register Company 222 Lansdowne Road Brockton Toronto, ON</div>')[0];
                popup_52ec038df2004937b6b5d95c3c365536.setContent(html_589892798e954698ac27e67daf51511a);
            

            circle_marker_dc87f79a75144a45aa5bc4add6f89bcb.bindPopup(popup_52ec038df2004937b6b5d95c3c365536)
            ;

            
        
    
            var circle_marker_6d3fe4a50be04d3b943affab694b817d = L.circleMarker(
                [43.64956, -79.38964],
                {
  "bubblingMouseEvents": true,
  "color": "blue",
  "dashArray": null,
  "dashOffset": null,
  "fill": true,
  "fillColor": "#3186cc",
  "fillOpacity": 0.7,
  "fillRule": "evenodd",
  "lineCap": "round",
  "lineJoin": "round",
  "opacity": 1.0,
  "radius": 5,
  "stroke": true,
  "weight": 3
}
                )
                .addTo(map_7bc78280a036424b88baeecf9c8eb27c);
            
    
            var popup_b99a02ac905544d99d4e17c5c9a3b0b2 = L.popup({maxWidth: '300'
            
            });

            
                var html_a9bb0eb5573e42249c7e62da9403e03a = $('<div id="html_a9bb0eb5573e42249c7e62da9403e03a" style="width: 100.0%; height: 100.0%;">Tip Top Tailors Warehouse 260 Richmond Street West Entertainment District Toronto, ON</div>')[0];
                popup_b99a02ac905544d99d4e17c5c9a3b0b2.setContent(html_a9bb0eb5573e42249c7e62da9403e03a);
            

            circle_marker_6d3fe4a50be04d3b943affab694b817d.bindPopup(popup_b99a02ac905544d99d4e17c5c9a3b0b2)
            ;

            
        
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x211688dc860>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_poi = get_pois_as_df()\n",
    "df_features=df_poi.copy()\n",
    "poi_mapper.fit(df_features)\n",
    "df_features= poi_mapper.transform(df_features)\n",
    "avail_interests = list(df_features.columns)\n",
    "df_user = get_user_profile(avail_interests, user_interests)\n",
    "\n",
    "df_poi=find_similarity(df_features, df_user, df_poi, sim_method='hamming') #hamming')#, sim_method='spatial')\n",
    "# print(df_poi.shape)\n",
    "\n",
    "df_filtered = find_points_in_area(df_poi, starting_lat, starting_long, num_points, max_distance)\n",
    "plot_stops(starting_lat, starting_long, df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[['name', 'address','latitude', 'longitude', 'poi_type_simple', 'sim_rating']]\n",
    "\n",
    "#str(df_filtered['poi_type_simple'].value_counts())\n",
    "num_art=len(df_filtered[df_filtered['poi_type_simple']=='Art'])\n",
    "num_building = len(df_filtered[df_filtered['poi_type_simple']=='Building'])\n",
    "num_plaque = len(df_filtered[df_filtered['poi_type_simple']=='Plaque'])\n",
    "\n",
    "stops = str(df_filtered['poi_id'].values)\n",
    "num_art, num_building, num_plaque,stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(0, 6, 1, '[4576 4668 4655 4582 4720 5142 5012]') Hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_features = df_features.as_matrix()\n",
    "U=df_user.as_matrix()\n",
    "site_prefs=[]\n",
    "# loop through rows of features and calculate cosine diff from user prefs\n",
    "for i in range(0,len(np_features)):\n",
    "    np_features[i,:]\n",
    "    result = spatial.distance.cosine(np_features[i,:], U)#, weight_of_importance)\n",
    "    # store in dictionary\n",
    "    res_dict = {'ix': i, 'dist': result}\n",
    "    site_prefs.append(res_dict)\n",
    "df_site_prefs = pd.DataFrame(site_prefs)\n",
    "df_site_prefs.sort_values('dist', ascending=False, inplace=True)\n",
    "df_site_prefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_features = df_features.as_matrix()\n",
    "# U=df_user.as_matrix()\n",
    "# site_prefs=[]\n",
    "# for i in range(0,len(np_features)):\n",
    "#     np_features[i,:]\n",
    "#     result = spatial.distance.cosine(np_features[i,:], U)#, weight_of_importance)\n",
    "#     res_dict = {'ix': i, 'dist': result}\n",
    "#     site_prefs.append(res_dict)\n",
    "# df_site_prefs = pd.DataFrame(site_prefs)\n",
    "# df_site_prefs.sort_values('dist', ascending=False, inplace=True)\n",
    "# df_site_prefs.head()\n",
    "# #user_matches.iloc[0:20,:]\n",
    "# for ix,row in df_site_prefs.iloc[0:20,:].iterrows():\n",
    "#     # now find matches close to target of interest\n",
    "#     print(df_poi.iloc[ix,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U=df_user.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_prefs=[]\n",
    "for i in range(0,len(np_features)):\n",
    "    np_features[i,:]\n",
    "    result = spatial.distance.cosine(np_features[i,:], U)#, weight_of_importance)\n",
    "    res_dict = {'ix': i, 'dist': result}\n",
    "    site_prefs.append(res_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_site_prefs = pd.DataFrame(site_prefs)\n",
    "df_site_prefs.sort_values('dist', ascending=False, inplace=True)\n",
    "df_site_prefs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_matches.iloc[0:20,:]\n",
    "for ix,row in df_site_prefs.iloc[0:20,:].iterrows():\n",
    "    # now find matches close to target of interest\n",
    "    print(df_poi.iloc[ix,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_stops = plot_stops(starting_lat, starting_long, df_filtered)\n",
    "# map_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_stops=find_optimal_route(df_filtered, starting_lat, starting_long,method='genetic')\n",
    "# map_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_stops=find_optimal_route(df_filtered, starting_lat, starting_long, method='google')\n",
    "# map_stops\n",
    "\n",
    "map_stops, guess, df_filtered, walk_stops, total_dist=find_optimal_route(df_filtered, starting_lat, starting_long, method='google')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_stops\n",
    "stops_ordered = []\n",
    "for stop in guess:\n",
    "    stops_ordered.append(walk_stops[stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log these results for later comparison\n",
    "stops_ordered\n",
    "df_filtered.sort_values(\"order\", inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store in log\n",
    "num, similary method, opimizer, starting point, duration, user_pref, # stops, total distance, avg distance between stops, total similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def store_walk_in_log():\n",
    "walknum += 1\n",
    "similarity_method = 'co-sine'\n",
    "optimizer = 'or'\n",
    "\n",
    "guess2=map(str,guess) \n",
    "guess2='-'.join(guess2)\n",
    "\n",
    "logging.debug(f\"{walknum}, {similarity_method}, {optimizer}, {starting_lat}, {starting_long}, {duration},\\\n",
    "              {num_points}, {total_dist}, {total_dist/num_points}, {0}, {guess2}, {df_filtered['sim_rating'].mean()}, \\\n",
    "                {df_filtered['sim_rating'].max()}, {user_profile} \")\n",
    "df_filtered.to_csv(f'../logs/walk_{walknum}.csv')\n",
    "df_user.to_csv(f'../logs/userprefs_{walknum}.csv')\n",
    "\n",
    "#add_stop_order_to_df(df, order_guess, key_to_use='poi_id'):\n",
    "#     starting_lat =43.647273\n",
    "# starting_long=-79.386560\n",
    "\n",
    "# walk_duration = 1 # in hours\n",
    "# num_points = 12\n",
    "# max_distance = 1000 # meters\n",
    "# df_user -- user prefs\n",
    "# df_poi -- has sim rating for each stop\n",
    "# max_dist\n",
    "#df_filtered['sim_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
